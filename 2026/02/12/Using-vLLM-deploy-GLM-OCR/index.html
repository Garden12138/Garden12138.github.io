<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Using vLLM deploy GLM OCR | 后端学习手记</title><meta name="author" content="Garden"><meta name="copyright" content="Garden"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="使用 vLLM Docker 部署 GLM-OCR 目标：在单卡服务器上，通过 Docker 启动 vLLM 的 OpenAI 兼容服务，加载 ZhipuAI&#x2F;GLM-OCR，支持读取本地挂载目录里的图片（file:&#x2F;&#x2F;&#x2F;media&#x2F;...）并输出严格 JSON，方便你直接解析字段。结论：当前链路下 PDF 不能直接作为 image 输入，需要先 PDF → 图片 再 OCR。   目录 1. 前">
<meta property="og:type" content="article">
<meta property="og:title" content="Using vLLM deploy GLM OCR">
<meta property="og:url" content="https://gardenqaq.cn/2026/02/12/Using-vLLM-deploy-GLM-OCR/index.html">
<meta property="og:site_name" content="后端学习手记">
<meta property="og:description" content="使用 vLLM Docker 部署 GLM-OCR 目标：在单卡服务器上，通过 Docker 启动 vLLM 的 OpenAI 兼容服务，加载 ZhipuAI&#x2F;GLM-OCR，支持读取本地挂载目录里的图片（file:&#x2F;&#x2F;&#x2F;media&#x2F;...）并输出严格 JSON，方便你直接解析字段。结论：当前链路下 PDF 不能直接作为 image 输入，需要先 PDF → 图片 再 OCR。   目录 1. 前">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gardenqaq.cn/img/saber.jpg">
<meta property="article:published_time" content="2026-02-12T07:36:22.000Z">
<meta property="article:modified_time" content="2026-02-12T07:37:46.878Z">
<meta property="article:author" content="Garden">
<meta property="article:tag" content="ai">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gardenqaq.cn/img/saber.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Using vLLM deploy GLM OCR",
  "url": "https://gardenqaq.cn/2026/02/12/Using-vLLM-deploy-GLM-OCR/",
  "image": "https://gardenqaq.cn/img/saber.jpg",
  "datePublished": "2026-02-12T07:36:22.000Z",
  "dateModified": "2026-02-12T07:37:46.878Z",
  "author": [
    {
      "@type": "Person",
      "name": "Garden",
      "url": "https://gardenqaq.cn/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/blue-cat.png"><link rel="canonical" href="https://gardenqaq.cn/2026/02/12/Using-vLLM-deploy-GLM-OCR/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Using vLLM deploy GLM OCR',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><script>(()=>{
  const $loadingBox = document.getElementById('loading-box')
  const $body = document.body
  const preloader = {
    endLoading: () => {
      $body.style.overflow = ''
      $loadingBox.classList.add('loaded')
    },
    initLoading: () => {
      $body.style.overflow = 'hidden'
      $loadingBox.classList.remove('loaded')
    }
  }

  preloader.initLoading()
  window.addEventListener('load', preloader.endLoading)

  if (false) {
    btf.addGlobalFn('pjaxSend', preloader.initLoading, 'preloader_init')
    btf.addGlobalFn('pjaxComplete', preloader.endLoading, 'preloader_end')
  }
})()</script><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/post_covers/Gemini_Generated_Image_nc24q6nc24q6nc24);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">后端学习手记</span></a><a class="nav-page-title" href="/"><span class="site-name">Using vLLM deploy GLM OCR</span></a></span><div id="menus"></div></nav><div id="post-info"><h1 class="post-title">Using vLLM deploy GLM OCR</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-02-12T07:36:22.000Z" title="发表于 2026-02-12 15:36:22">2026-02-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-12T07:37:46.878Z" title="更新于 2026-02-12 15:37:46">2026-02-12</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1 id="使用-vLLM-Docker-部署-GLM-OCR"><a href="#使用-vLLM-Docker-部署-GLM-OCR" class="headerlink" title="使用 vLLM Docker 部署 GLM-OCR"></a>使用 vLLM Docker 部署 GLM-OCR</h1><blockquote>
<p>目标：在单卡服务器上，通过 Docker 启动 vLLM 的 OpenAI 兼容服务，加载 <code>ZhipuAI/GLM-OCR</code>，支持读取本地挂载目录里的图片（<code>file:///media/...</code>）并输出<strong>严格 JSON</strong>，方便你直接解析字段。<br>结论：当前链路下 <strong>PDF 不能直接作为 image 输入</strong>，需要先 <strong>PDF → 图片</strong> 再 OCR。</p>
</blockquote>
<hr>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul>
<li><a href="#1-%E5%89%8D%E7%BD%AE%E6%9D%A1%E4%BB%B6">1. 前置条件</a></li>
<li><a href="#2-%E7%9B%AE%E5%BD%95%E8%A7%84%E5%88%92">2. 目录规划</a></li>
<li><a href="#3-%E6%8E%A8%E8%8D%90%E5%AE%BF%E4%B8%BB%E6%9C%BA%E9%A2%84%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8Bmodelscope-download">3. （推荐）宿主机预下载模型：ModelScope download</a></li>
<li><a href="#4-%E4%B8%80%E9%94%AE%E5%90%AF%E5%8A%A8-vllm--glm-ocrdocker">4. 一键启动 vLLM + GLM-OCR（Docker）</a></li>
<li><a href="#5-%E5%90%AF%E5%8A%A8%E9%AA%8C%E8%AF%81%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%A3%80%E6%9F%A5%E5%91%BD%E4%BB%A4">5. 启动验证与常用检查命令</a></li>
<li><a href="#6-pdf-%E8%BD%AC%E5%9B%BE%E7%89%87">6. PDF 转图片</a></li>
<li><a href="#7-%E8%B0%83%E7%94%A8%E6%8E%A5%E5%8F%A3%E5%8F%91%E7%A5%A8-ocr-%E5%B9%B6%E4%B8%A5%E6%A0%BC%E8%BE%93%E5%87%BA-json">7. 调用接口：发票 OCR 并严格输出 JSON</a></li>
<li><a href="#8-%E7%BB%93%E6%9E%9C%E8%A7%A3%E6%9E%90%E5%A6%82%E4%BD%95%E5%8F%96%E6%AF%8F%E4%B8%AA%E5%AD%97%E6%AE%B5">8. 结果解析：如何取每个字段</a></li>
<li><a href="#9-%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99%E4%B8%8E%E4%B8%80%E8%A1%8C%E4%BF%AE%E5%A4%8D">9. 常见报错与一行修复</a></li>
<li><a href="#10-%E5%8F%AF%E9%80%89%E4%BC%98%E5%8C%96">10. 可选优化</a></li>
</ul>
<hr>
<h2 id="1-前置条件"><a href="#1-前置条件" class="headerlink" title="1. 前置条件"></a>1. 前置条件</h2><h3 id="1-1-GPU-驱动-Docker"><a href="#1-1-GPU-驱动-Docker" class="headerlink" title="1.1 GPU &#x2F; 驱动 &#x2F; Docker"></a>1.1 GPU &#x2F; 驱动 &#x2F; Docker</h3><p>确保以下命令正常：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br><span class="line">docker version</span><br></pre></td></tr></table></figure>

<p>同时需要 NVIDIA Container Toolkit（保证容器能用 GPU）。</p>
<hr>
<h2 id="2-目录规划"><a href="#2-目录规划" class="headerlink" title="2. 目录规划"></a>2. 目录规划</h2><p>我们使用三个宿主机目录（与最终部署命令保持一致）：</p>
<ul>
<li><strong>媒体文件目录（只读挂载）</strong>：<code>~/_Work/glm-ocr/media</code><ul>
<li>放待识别的图片、以及 PDF 转出来的图片</li>
</ul>
</li>
<li><strong>页图片目录</strong>：<code>~/_Work/glm-ocr/media/pages</code><ul>
<li>用于存放 <code>pdftoppm</code> 输出的每页 PNG</li>
</ul>
</li>
<li><strong>pip 缓存目录（可写挂载）</strong>：<code>~/_Work/glm-ocr/pip-cache</code><ul>
<li>用于缓存 pip 下载的 wheel&#x2F;sdist，加速重启</li>
</ul>
</li>
</ul>
<p>创建目录：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -p ~/_Work/glm-ocr/media</span><br><span class="line"><span class="built_in">mkdir</span> -p ~/_Work/glm-ocr/media/pages</span><br><span class="line"><span class="built_in">mkdir</span> -p ~/_Work/glm-ocr/pip-cache</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="3-（推荐）宿主机预下载模型：ModelScope-download"><a href="#3-（推荐）宿主机预下载模型：ModelScope-download" class="headerlink" title="3. （推荐）宿主机预下载模型：ModelScope download"></a>3. （推荐）宿主机预下载模型：ModelScope download</h2><p>目的：避免容器首次启动时“边下载边加载”导致等待时间长或失败；也方便离线&#x2F;内网部署。</p>
<h3 id="3-1-宿主机安装-modelscope"><a href="#3-1-宿主机安装-modelscope" class="headerlink" title="3.1 宿主机安装 modelscope"></a>3.1 宿主机安装 modelscope</h3><p>在宿主机上执行（系统 Python 或 conda 环境均可）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -U modelscope</span><br></pre></td></tr></table></figure>

<h3 id="3-2-预下载模型"><a href="#3-2-预下载模型" class="headerlink" title="3.2 预下载模型"></a>3.2 预下载模型</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modelscope download --model ZhipuAI/GLM-OCR</span><br></pre></td></tr></table></figure>

<p>默认会落在 <code>~/.cache/modelscope</code> 下（常见路径：<code>~/.cache/modelscope/hub/models/...</code>）。</p>
<h3 id="3-3-验证模型缓存是否存在"><a href="#3-3-验证模型缓存是否存在" class="headerlink" title="3.3 验证模型缓存是否存在"></a>3.3 验证模型缓存是否存在</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ls</span> -lah ~/.cache/modelscope/hub/models/ZhipuAI/GLM-OCR | <span class="built_in">head</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>关键点：后面 Docker 启动时会把 <code>~/.cache/modelscope</code> 挂到容器的 <code>/root/.cache/modelscope</code>，从而复用缓存。</p>
</blockquote>
<hr>
<h2 id="4-一键启动-vLLM-GLM-OCR（Docker）"><a href="#4-一键启动-vLLM-GLM-OCR（Docker）" class="headerlink" title="4. 一键启动 vLLM + GLM-OCR（Docker）"></a>4. 一键启动 vLLM + GLM-OCR（Docker）</h2><p>下面这条是你当前验证可用的启动命令（可直接复制）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker run -d --name vllm-glm-ocr \</span><br><span class="line">  --entrypoint bash \</span><br><span class="line">  --gpus <span class="string">&#x27;&quot;device=3&quot;&#x27;</span> \</span><br><span class="line">  -p 8181:8080 \</span><br><span class="line">  --ipc=host \</span><br><span class="line">  --shm-size=8g \</span><br><span class="line">  --restart unless-stopped \</span><br><span class="line">  -e VLLM_USE_MODELSCOPE=<span class="literal">true</span> \</span><br><span class="line">  -e VLLM_API_KEY=sk-REPLACE_ME \</span><br><span class="line">  -v ~/.cache/modelscope:/root/.cache/modelscope \</span><br><span class="line">  -v ~/_Work/glm-ocr/media:/media:ro \</span><br><span class="line">  -v ~/_Work/glm-ocr/pip-cache:/root/.cache/pip \</span><br><span class="line">  vllm/vllm-openai:nightly \</span><br><span class="line">  -lc <span class="string">&#x27;pip install -U modelscope transformers==5.1.0 &amp;&amp; \</span></span><br><span class="line"><span class="string">       exec vllm serve ZhipuAI/GLM-OCR \</span></span><br><span class="line"><span class="string">         --host 0.0.0.0 \</span></span><br><span class="line"><span class="string">         --port 8080 \</span></span><br><span class="line"><span class="string">         --api-key &quot;$VLLM_API_KEY&quot; \</span></span><br><span class="line"><span class="string">         --served-model-name glm-ocr \</span></span><br><span class="line"><span class="string">         --trust-remote-code \</span></span><br><span class="line"><span class="string">         --allowed-local-media-path /media \</span></span><br><span class="line"><span class="string">         -tp 1 \</span></span><br><span class="line"><span class="string">         --gpu-memory-utilization 0.5 \</span></span><br><span class="line"><span class="string">         --max-model-len 4096&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="4-1-关键参数说明（少踩坑版）"><a href="#4-1-关键参数说明（少踩坑版）" class="headerlink" title="4.1 关键参数说明（少踩坑版）"></a>4.1 关键参数说明（少踩坑版）</h3><p><strong>Docker 层：</strong></p>
<ul>
<li><code>--gpus &#39;&quot;device=3&quot;&#39;</code>：只使用第 4 张 GPU（从 0 开始编号）</li>
<li><code>-p 8181:8080</code>：宿主机 <code>8181</code> 映射到容器 <code>8080</code></li>
<li><code>--ipc=host</code>：共享 IPC 命名空间，减少多进程&#x2F;共享内存相关问题</li>
<li><code>--shm-size=8g</code>：增大 <code>/dev/shm</code>，避免默认 64MB 导致异常</li>
<li><code>-v ~/_Work/glm-ocr/media:/media:ro</code>：媒体目录只读挂载为容器 <code>/media</code></li>
<li><code>-v ~/_Work/glm-ocr/pip-cache:/root/.cache/pip</code>：pip 缓存（<strong>目录对目录</strong>）</li>
</ul>
<p><strong>vLLM &#x2F; 模型层：</strong></p>
<ul>
<li><code>VLLM_USE_MODELSCOPE=true</code>：通过 ModelScope 加载&#x2F;缓存</li>
<li><code>--api-key &quot;$VLLM_API_KEY&quot;</code>：OpenAI 兼容鉴权</li>
<li><code>--served-model-name glm-ocr</code>：对外暴露的 model 名固定为 <code>glm-ocr</code>（调用方更统一）</li>
<li><code>--trust-remote-code</code>：多模态模型常用；建议保留</li>
<li><code>--allowed-local-media-path /media</code>：只允许读取 <code>file:///media/...</code> 下的本地文件</li>
<li><code>-tp 1</code>：单卡必须 1（否则会报“world size &gt; available gpus”）</li>
<li><code>--gpu-memory-utilization 0.5</code> + <code>--max-model-len 4096</code>：控制 KV cache &#x2F; 显存占用，避免默认超长上下文导致显存不足</li>
</ul>
<hr>
<h2 id="5-启动验证与常用检查命令"><a href="#5-启动验证与常用检查命令" class="headerlink" title="5. 启动验证与常用检查命令"></a>5. 启动验证与常用检查命令</h2><h3 id="5-1-容器是否在跑"><a href="#5-1-容器是否在跑" class="headerlink" title="5.1 容器是否在跑"></a>5.1 容器是否在跑</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker ps -a | grep vllm-glm-ocr</span><br></pre></td></tr></table></figure>

<h3 id="5-2-看启动日志"><a href="#5-2-看启动日志" class="headerlink" title="5.2 看启动日志"></a>5.2 看启动日志</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker logs --<span class="built_in">tail</span> 120 vllm-glm-ocr</span><br></pre></td></tr></table></figure>

<h3 id="5-3-验证模型列表（服务就绪后）"><a href="#5-3-验证模型列表（服务就绪后）" class="headerlink" title="5.3 验证模型列表（服务就绪后）"></a>5.3 验证模型列表（服务就绪后）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -H <span class="string">&quot;Authorization: Bearer sk-REPLACE_ME&quot;</span> http://127.0.0.1:8181/v1/models</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：端口是 <strong>8181</strong>（来自 <code>-p 8181:8080</code>），不要写错。</p>
</blockquote>
<h3 id="5-4-容器内确认能看到媒体文件"><a href="#5-4-容器内确认能看到媒体文件" class="headerlink" title="5.4 容器内确认能看到媒体文件"></a>5.4 容器内确认能看到媒体文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker <span class="built_in">exec</span> -it vllm-glm-ocr bash -lc <span class="string">&quot;ls -lah /media | head&quot;</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="6-PDF-转图片"><a href="#6-PDF-转图片" class="headerlink" title="6. PDF 转图片"></a>6. PDF 转图片</h2><p>GLM-OCR 在这个链路里会把输入当“图片”解码，<strong>PDF 直接传会报错</strong>（PIL 无法识别）。建议先转成 PNG：</p>
<p>安装工具：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get update</span><br><span class="line"><span class="built_in">sudo</span> apt-get install -y poppler-utils</span><br></pre></td></tr></table></figure>

<p>转换（每页一张，200 DPI）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pdftoppm -png -r 200 ~/_Work/glm-ocr/media/fp.pdf ~/_Work/glm-ocr/media/pages/fp</span><br><span class="line"><span class="built_in">ls</span> -lah ~/_Work/glm-ocr/media/pages | <span class="built_in">head</span></span><br></pre></td></tr></table></figure>

<p>常见输出文件名：<code>fp-1.png</code>, <code>fp-2.png</code>, …</p>
<hr>
<h2 id="7-调用接口：发票-OCR-并严格输出-JSON"><a href="#7-调用接口：发票-OCR-并严格输出-JSON" class="headerlink" title="7. 调用接口：发票 OCR 并严格输出 JSON"></a>7. 调用接口：发票 OCR 并严格输出 JSON</h2><p>下面是你当前可用的请求方式：用强约束提示词，让模型<strong>只输出严格 JSON</strong>（字段与模板完全一致）。</p>
<blockquote>
<p>关键：图片 URL 必须是容器路径：<code>file:///media/...</code><br>不能传宿主机路径（例如 <code>/home/bj-ai/_Work/...</code>），否则会触发安全限制报错。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">curl http://127.0.0.1:8181/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer sk-REPLACE_ME&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;glm-ocr&quot;,</span></span><br><span class="line"><span class="string">    &quot;temperature&quot;: 0,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [&#123;</span></span><br><span class="line"><span class="string">      &quot;role&quot;: &quot;user&quot;,</span></span><br><span class="line"><span class="string">      &quot;content&quot;: [</span></span><br><span class="line"><span class="string">        &#123;&quot;type&quot;:&quot;text&quot;,&quot;text&quot;:&quot;请对图片做发票OCR并抽取字段。你只能输出严格 JSON，必须与下面模板字段完全一致（不能增删字段）。缺失填 null；所有数值字段用字符串。\n模板：\n&#123;\n  \&quot;invoice_type\&quot;: null,\n  \&quot;invoice_no\&quot;: null,\n  \&quot;invoice_date\&quot;: null,\n  \&quot;buyer_name\&quot;: null,\n  \&quot;buyer_tax_id\&quot;: null,\n  \&quot;seller_name\&quot;: null,\n  \&quot;seller_tax_id\&quot;: null,\n  \&quot;item_name\&quot;: null,\n  \&quot;spec_model\&quot;: null,\n  \&quot;unit\&quot;: null,\n  \&quot;qty\&quot;: null,\n  \&quot;unit_price\&quot;: null,\n  \&quot;amount_excl_tax\&quot;: null,\n  \&quot;tax_rate\&quot;: null,\n  \&quot;tax_amount\&quot;: null,\n  \&quot;total_excl_tax\&quot;: null,\n  \&quot;total_tax\&quot;: null,\n  \&quot;total_amount\&quot;: null,\n  \&quot;total_amount_cn\&quot;: null,\n  \&quot;remark\&quot;: null,\n  \&quot;issuer\&quot;: null\n&#125;\n注意：只输出 JSON 本体，不要任何解释。&quot;&#125;,</span></span><br><span class="line"><span class="string">        &#123;&quot;type&quot;:&quot;image_url&quot;,&quot;image_url&quot;:&#123;&quot;url&quot;:&quot;file:///media/pages/fp-1.png&quot;&#125;&#125;</span></span><br><span class="line"><span class="string">      ]</span></span><br><span class="line"><span class="string">    &#125;]</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="8-结果解析：如何取每个字段"><a href="#8-结果解析：如何取每个字段" class="headerlink" title="8. 结果解析：如何取每个字段"></a>8. 结果解析：如何取每个字段</h2><p>vLLM OpenAI 兼容返回里，你要的内容在：</p>
<ul>
<li><code>choices[0].message.content</code></li>
</ul>
<p>因为你要求模型输出严格 JSON，所以它应该是一个 JSON 字符串。示例 Python：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">resp = ...  <span class="comment"># 你的 HTTP 响应 JSON（dict）</span></span><br><span class="line">content = resp[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;message&quot;</span>][<span class="string">&quot;content&quot;</span>]</span><br><span class="line"></span><br><span class="line">data = json.loads(content)  <span class="comment"># 变成 dict</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;发票号:&quot;</span>, data[<span class="string">&quot;invoice_no&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;金额:&quot;</span>, data[<span class="string">&quot;total_amount&quot;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;购买方:&quot;</span>, data[<span class="string">&quot;buyer_name&quot;</span>])</span><br></pre></td></tr></table></figure>

<blockquote>
<p>建议：生产环境加一个容错（比如截取第一个 <code>&#123;</code> 到最后一个 <code>&#125;</code> 再 <code>json.loads</code>），防止偶发多输出字符。</p>
</blockquote>
<hr>
<h2 id="9-常见报错与一行修复"><a href="#9-常见报错与一行修复" class="headerlink" title="9. 常见报错与一行修复"></a>9. 常见报错与一行修复</h2><h3 id="9-1-连接被拒绝-端口错误"><a href="#9-1-连接被拒绝-端口错误" class="headerlink" title="9.1 连接被拒绝 &#x2F; 端口错误"></a>9.1 连接被拒绝 &#x2F; 端口错误</h3><p>你映射的是 <code>8181:8080</code>，所以访问 <code>8181</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://127.0.0.1:8181/v1/models -H <span class="string">&quot;Authorization: Bearer sk-REPLACE_ME&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="9-2-World-size-2-available-GPUs-1"><a href="#9-2-World-size-2-available-GPUs-1" class="headerlink" title="9.2 World size (2) &gt; available GPUs (1)"></a>9.2 <code>World size (2) &gt; available GPUs (1)</code></h3><p>单卡必须：</p>
<ul>
<li><code>-tp 1</code></li>
</ul>
<h3 id="9-3-must-be-a-subpath-of-allowed-local-media-path-media"><a href="#9-3-must-be-a-subpath-of-allowed-local-media-path-media" class="headerlink" title="9.3 must be a subpath of --allowed-local-media-path /media"></a>9.3 <code>must be a subpath of --allowed-local-media-path /media</code></h3><p>请求里传了宿主机路径。修复：</p>
<ul>
<li>只用 <code>file:///media/...</code></li>
</ul>
<h3 id="9-4-显存-KV-cache-不足（默认-131072）"><a href="#9-4-显存-KV-cache-不足（默认-131072）" class="headerlink" title="9.4 显存 &#x2F; KV cache 不足（默认 131072）"></a>9.4 显存 &#x2F; KV cache 不足（默认 131072）</h3><p>修复思路：</p>
<ul>
<li>降低 <code>--max-model-len</code>（如 4096&#x2F;8192）</li>
<li>或提高 <code>--gpu-memory-utilization</code>（如 0.55&#x2F;0.6）</li>
</ul>
<p>你当前组合：<code>--max-model-len 4096</code> + <code>--gpu-memory-utilization 0.5</code> 更稳。</p>
<h3 id="9-5-cannot-identify-image-file（你传了-PDF）"><a href="#9-5-cannot-identify-image-file（你传了-PDF）" class="headerlink" title="9.5 cannot identify image file（你传了 PDF）"></a>9.5 <code>cannot identify image file</code>（你传了 PDF）</h3><p>修复：</p>
<ul>
<li>先 <code>pdftoppm</code> 转 PNG，再把 PNG 作为 <code>image_url</code> 传入</li>
</ul>
<hr>
<h2 id="10-可选优化"><a href="#10-可选优化" class="headerlink" title="10. 可选优化"></a>10. 可选优化</h2><ul>
<li><strong>自建镜像</strong>：把 <code>pip install -U modelscope transformers==5.1.0</code> 烘进去，避免每次启动都安装依赖</li>
<li><strong>自动化脚本</strong>：PDF → 多页 PNG → 逐页 OCR → 合并输出（适用于批处理）</li>
<li><strong>安全</strong>：把 <code>VLLM_API_KEY</code> 换成强 key；避免对公网暴露端口</li>
</ul>
<hr>
<h2 id="附：停止-重启容器"><a href="#附：停止-重启容器" class="headerlink" title="附：停止&#x2F;重启容器"></a>附：停止&#x2F;重启容器</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> docker logs -f vllm-glm-ocr</span><br><span class="line"><span class="built_in">sudo</span> docker restart vllm-glm-ocr</span><br><span class="line"><span class="built_in">sudo</span> docker stop vllm-glm-ocr</span><br><span class="line"><span class="built_in">sudo</span> docker <span class="built_in">rm</span> -f vllm-glm-ocr</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://gardenqaq.cn">Garden</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://gardenqaq.cn/2026/02/12/Using-vLLM-deploy-GLM-OCR/">https://gardenqaq.cn/2026/02/12/Using-vLLM-deploy-GLM-OCR/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://gardenqaq.cn" target="_blank">后端学习手记</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/ai/">ai</a></div><div class="post-share"><div class="social-share" data-image="/img/saber.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2026/02/10/Using-the-dify-subworkflow/" title="Using the dify subworkflow"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/Gemini_Generated_Image_23xz5423xz5423xz.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">Using the dify subworkflow</div></div><div class="info-2"><div class="info-item-1">介绍如何在 dify 中将复杂工作流拆分为子工作流并发布为工具复用，以个人助手调用发票识别子工作流为例，涵盖子工作流创建、发布、主工作流中工具节点配置与运行测试的完整实践流程。</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/11/03/AI-video-face-swapping-implementation-methods/" title="AI video face-swapping implementation methods.md"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/Google_AI_Studio_2025-11-03T06_39_30.260Z.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-03</div><div class="info-item-2">AI video face-swapping implementation methods.md</div></div><div class="info-2"><div class="info-item-1">调研基于 Wan2.2-Animate 的视频换脸实现方式，覆盖 HuggingFace、ModelScope、Wan 平台、ComfyUI（在线/本地）流程、优缺点与关键模型配置。</div></div></div></a><a class="pagination-related" href="/2025/10/15/BPE-algorithm-analysis/" title="BPE algorithm analysis"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/ChatGPT_Image_20251015.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-15</div><div class="info-item-2">BPE algorithm analysis</div></div><div class="info-2"><div class="info-item-1">深入解析BPE（Byte Pair Encoding）算法的工作原理，包括训练流程和应用流程，通过迭代合并高频字符对来构建词汇表，有效解决NLP中的罕见词问题。</div></div></div></a><a class="pagination-related" href="/2025/10/16/Business-license-OCR-implementation/" title="Business license OCR implementation"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/ChatGPT_Image_20251016.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-10-16</div><div class="info-item-2">Business license OCR implementation</div></div><div class="info-2"><div class="info-item-1">基于FastAPI框架实现营业执照OCR识别系统，集成读光票证检测矫正模型和Nanonets-OCR-s模型，自动识别营业执照中的统一社会信用代码、名称、法定代表人、住所等关键信息。</div></div></div></a><a class="pagination-related" href="/2025/06/30/DB-GPT-usage/" title="DB-GPT usage"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/133049767_p2.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-06-30</div><div class="info-item-2">DB-GPT usage</div></div><div class="info-2"><div class="info-item-1">DB-GPT是一个开源的AI原生数据应用开发框架，目的是构建大模型领域的基础设施，通过开发多模型管理(SMMF)、Text2SQL效果优化、RAG框架以及优化、Multi-Agents框架协作、AWEL(智能体工作流编排)等多种技术能力，让围绕数据库构建大模型应用更简单，更方便。</div></div></div></a><a class="pagination-related" href="/2025/07/15/Download-model/" title="Download model"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/133049767_p1.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-07-15</div><div class="info-item-2">Download model</div></div><div class="info-2"><div class="info-item-1">下载模型，使开发者可在本地环境微调或运行推理模型。</div></div></div></a><a class="pagination-related" href="/2026/01/29/Deploying-Step3-VL-10B-using-vLLM-multi-GPU-inference/" title="Deploying Step3-VL-10B using vLLM multi-GPU inference"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/Gemini_Generated_Image_v8zw8jv8zw8jv8zw.png" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2026-01-29</div><div class="info-item-2">Deploying Step3-VL-10B using vLLM multi-GPU inference</div></div><div class="info-2"><div class="info-item-1">介绍在 Ubuntu 22.04 + 多张 22GB GPU 服务器上，通过 vLLM OpenAI API Server 部署 Step3-VL-10B 模型的完整流程，包括 NVIDIA 驱动与 CUDA 配置、Docker GPU 环境搭建、ModelScope 模型缓存、vLLM 多卡 Tensor Parallel 启动参数以及接入 dify 工作流的实战案例。</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/saber.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">Garden</div><div class="author-info-description"></div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Garden12138"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is Garden's Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8-vLLM-Docker-%E9%83%A8%E7%BD%B2-GLM-OCR"><span class="toc-number">1.</span> <span class="toc-text">使用 vLLM Docker 部署 GLM-OCR</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E5%BD%95"><span class="toc-number">1.1.</span> <span class="toc-text">目录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%89%8D%E7%BD%AE%E6%9D%A1%E4%BB%B6"><span class="toc-number">1.2.</span> <span class="toc-text">1. 前置条件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-GPU-%E9%A9%B1%E5%8A%A8-Docker"><span class="toc-number">1.2.1.</span> <span class="toc-text">1.1 GPU &#x2F; 驱动 &#x2F; Docker</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%9B%AE%E5%BD%95%E8%A7%84%E5%88%92"><span class="toc-number">1.3.</span> <span class="toc-text">2. 目录规划</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%EF%BC%88%E6%8E%A8%E8%8D%90%EF%BC%89%E5%AE%BF%E4%B8%BB%E6%9C%BA%E9%A2%84%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B%EF%BC%9AModelScope-download"><span class="toc-number">1.4.</span> <span class="toc-text">3. （推荐）宿主机预下载模型：ModelScope download</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%AE%BF%E4%B8%BB%E6%9C%BA%E5%AE%89%E8%A3%85-modelscope"><span class="toc-number">1.4.1.</span> <span class="toc-text">3.1 宿主机安装 modelscope</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E9%A2%84%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.4.2.</span> <span class="toc-text">3.2 预下载模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E7%BC%93%E5%AD%98%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8"><span class="toc-number">1.4.3.</span> <span class="toc-text">3.3 验证模型缓存是否存在</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E4%B8%80%E9%94%AE%E5%90%AF%E5%8A%A8-vLLM-GLM-OCR%EF%BC%88Docker%EF%BC%89"><span class="toc-number">1.5.</span> <span class="toc-text">4. 一键启动 vLLM + GLM-OCR（Docker）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%85%B3%E9%94%AE%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E%EF%BC%88%E5%B0%91%E8%B8%A9%E5%9D%91%E7%89%88%EF%BC%89"><span class="toc-number">1.5.1.</span> <span class="toc-text">4.1 关键参数说明（少踩坑版）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%90%AF%E5%8A%A8%E9%AA%8C%E8%AF%81%E4%B8%8E%E5%B8%B8%E7%94%A8%E6%A3%80%E6%9F%A5%E5%91%BD%E4%BB%A4"><span class="toc-number">1.6.</span> <span class="toc-text">5. 启动验证与常用检查命令</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E5%AE%B9%E5%99%A8%E6%98%AF%E5%90%A6%E5%9C%A8%E8%B7%91"><span class="toc-number">1.6.1.</span> <span class="toc-text">5.1 容器是否在跑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E7%9C%8B%E5%90%AF%E5%8A%A8%E6%97%A5%E5%BF%97"><span class="toc-number">1.6.2.</span> <span class="toc-text">5.2 看启动日志</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E9%AA%8C%E8%AF%81%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8%EF%BC%88%E6%9C%8D%E5%8A%A1%E5%B0%B1%E7%BB%AA%E5%90%8E%EF%BC%89"><span class="toc-number">1.6.3.</span> <span class="toc-text">5.3 验证模型列表（服务就绪后）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E5%AE%B9%E5%99%A8%E5%86%85%E7%A1%AE%E8%AE%A4%E8%83%BD%E7%9C%8B%E5%88%B0%E5%AA%92%E4%BD%93%E6%96%87%E4%BB%B6"><span class="toc-number">1.6.4.</span> <span class="toc-text">5.4 容器内确认能看到媒体文件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-PDF-%E8%BD%AC%E5%9B%BE%E7%89%87"><span class="toc-number">1.7.</span> <span class="toc-text">6. PDF 转图片</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E8%B0%83%E7%94%A8%E6%8E%A5%E5%8F%A3%EF%BC%9A%E5%8F%91%E7%A5%A8-OCR-%E5%B9%B6%E4%B8%A5%E6%A0%BC%E8%BE%93%E5%87%BA-JSON"><span class="toc-number">1.8.</span> <span class="toc-text">7. 调用接口：发票 OCR 并严格输出 JSON</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-%E7%BB%93%E6%9E%9C%E8%A7%A3%E6%9E%90%EF%BC%9A%E5%A6%82%E4%BD%95%E5%8F%96%E6%AF%8F%E4%B8%AA%E5%AD%97%E6%AE%B5"><span class="toc-number">1.9.</span> <span class="toc-text">8. 结果解析：如何取每个字段</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#9-%E5%B8%B8%E8%A7%81%E6%8A%A5%E9%94%99%E4%B8%8E%E4%B8%80%E8%A1%8C%E4%BF%AE%E5%A4%8D"><span class="toc-number">1.10.</span> <span class="toc-text">9. 常见报错与一行修复</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-%E8%BF%9E%E6%8E%A5%E8%A2%AB%E6%8B%92%E7%BB%9D-%E7%AB%AF%E5%8F%A3%E9%94%99%E8%AF%AF"><span class="toc-number">1.10.1.</span> <span class="toc-text">9.1 连接被拒绝 &#x2F; 端口错误</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-World-size-2-available-GPUs-1"><span class="toc-number">1.10.2.</span> <span class="toc-text">9.2 World size (2) &gt; available GPUs (1)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-must-be-a-subpath-of-allowed-local-media-path-media"><span class="toc-number">1.10.3.</span> <span class="toc-text">9.3 must be a subpath of --allowed-local-media-path &#x2F;media</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-%E6%98%BE%E5%AD%98-KV-cache-%E4%B8%8D%E8%B6%B3%EF%BC%88%E9%BB%98%E8%AE%A4-131072%EF%BC%89"><span class="toc-number">1.10.4.</span> <span class="toc-text">9.4 显存 &#x2F; KV cache 不足（默认 131072）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-5-cannot-identify-image-file%EF%BC%88%E4%BD%A0%E4%BC%A0%E4%BA%86-PDF%EF%BC%89"><span class="toc-number">1.10.5.</span> <span class="toc-text">9.5 cannot identify image file（你传了 PDF）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-%E5%8F%AF%E9%80%89%E4%BC%98%E5%8C%96"><span class="toc-number">1.11.</span> <span class="toc-text">10. 可选优化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%EF%BC%9A%E5%81%9C%E6%AD%A2-%E9%87%8D%E5%90%AF%E5%AE%B9%E5%99%A8"><span class="toc-number">1.12.</span> <span class="toc-text">附：停止&#x2F;重启容器</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/12/Using-vLLM-deploy-GLM-OCR/" title="Using vLLM deploy GLM OCR"><div style="background: /img/post_covers/Gemini_Generated_Image_nc24q6nc24q6nc24"></div></a><div class="content"><a class="title" href="/2026/02/12/Using-vLLM-deploy-GLM-OCR/" title="Using vLLM deploy GLM OCR">Using vLLM deploy GLM OCR</a><time datetime="2026-02-12T07:36:22.000Z" title="发表于 2026-02-12 15:36:22">2026-02-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/10/Using-the-dify-subworkflow/" title="Using the dify subworkflow"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/Gemini_Generated_Image_23xz5423xz5423xz.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Using the dify subworkflow"/></a><div class="content"><a class="title" href="/2026/02/10/Using-the-dify-subworkflow/" title="Using the dify subworkflow">Using the dify subworkflow</a><time datetime="2026-02-10T02:28:15.000Z" title="发表于 2026-02-10 10:28:15">2026-02-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/01/29/Deploying-Step3-VL-10B-using-vLLM-multi-GPU-inference/" title="Deploying Step3-VL-10B using vLLM multi-GPU inference"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/Gemini_Generated_Image_v8zw8jv8zw8jv8zw.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Deploying Step3-VL-10B using vLLM multi-GPU inference"/></a><div class="content"><a class="title" href="/2026/01/29/Deploying-Step3-VL-10B-using-vLLM-multi-GPU-inference/" title="Deploying Step3-VL-10B using vLLM multi-GPU inference">Deploying Step3-VL-10B using vLLM multi-GPU inference</a><time datetime="2026-01-29T06:40:30.000Z" title="发表于 2026-01-29 14:40:30">2026-01-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/31/Running-the-Funasr-Nano-2512-model-locally/" title="Running the Funasr-Nano-2512 model locally"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/Gemini_Generated_Image_ny0gpvny0gpvny0g.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Running the Funasr-Nano-2512 model locally"/></a><div class="content"><a class="title" href="/2025/12/31/Running-the-Funasr-Nano-2512-model-locally/" title="Running the Funasr-Nano-2512 model locally">Running the Funasr-Nano-2512 model locally</a><time datetime="2025-12-31T02:04:26.000Z" title="发表于 2025-12-31 10:04:26">2025-12-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/12/31/Using-NLLB-to-implement-language-translation/" title="Using NLLB to implement language translation"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/post_covers/Gemini_Generated_Image_cwtjtecwtjtecwtj.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Using NLLB to implement language translation"/></a><div class="content"><a class="title" href="/2025/12/31/Using-NLLB-to-implement-language-translation/" title="Using NLLB to implement language translation">Using NLLB to implement language translation</a><time datetime="2025-12-31T01:32:07.000Z" title="发表于 2025-12-31 09:32:07">2025-12-31</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(/img/post_covers/Gemini_Generated_Image_nc24q6nc24q6nc24);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2026 By Garden</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.5</a></div><div class="footer_custom_text"><a href="https://beian.miit.gov.cn" target="_blank" rel="noopener noreferrer">粤ICP备2025394033号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-heart.min.js" async="async" mobile="false"></script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/click-show-text.min.js" data-mobile="false" data-text="I,LOVE,YOU" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>